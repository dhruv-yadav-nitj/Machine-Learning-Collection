{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ySa3BHFWhAbT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoGycpFxhOi-",
        "outputId": "0bb464d6-dc1e-4092-85b3-7ef8e3ae9902"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7deb7c33e650>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "QgD2lyh9itLL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are we gonna do?**\n",
        "\n",
        "We would train the model on MNIST dataset and then fine tune the model on a particular digit to compare the results from pre-trained model and fine-tuned model."
      ],
      "metadata": {
        "id": "M3SEcFjjhduD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10)\n"
      ],
      "metadata": {
        "id": "Byra7p0WhYDm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__ (self, h1: int=1000, h2: int=2000):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(28*28, h1)  # MNIST images are of size (28, 28) -> for Linear Layers -> flatten the images -> 28 * 28\n",
        "        self.linear2 = nn.Linear(h1, h2)\n",
        "        self.linear3 = nn.Linear(h2, 10)  # MNIST images have 10 classes\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = x.view(-1, 28*28)  # (batch_size, 28, 28) -> (batch_size, 784)\n",
        "        out = self.relu(self.linear1(x))\n",
        "        out = self.relu(self.linear2(out))\n",
        "        out = self.linear3(out)\n",
        "        return out\n",
        "\n",
        "net = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "E94_4eC5iJ82"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simulating pre-training of the model**\n",
        "\n",
        "Here we would be using just 1 epoch (since the model is complex enough to learn the patterns)."
      ],
      "metadata": {
        "id": "AbCJwYehlVWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, epochs, total_iterations_limit: Optional[int]=None):\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    total_iterations = 0  # total number of batches of data we have traversed upon across all the epochs\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        data_iterator = tqdm(train_loader, desc=f'Epoch: {epoch+1}')\n",
        "\n",
        "        if total_iterations_limit is not None:\n",
        "            data_iterator.total = total_iterations_limit\n",
        "        for data in data_iterator:\n",
        "            x, y = data\n",
        "            total_iterations += 1\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(x)\n",
        "\n",
        "            loss = loss_fn(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
        "                return\n",
        "\n",
        "train(net, train_loader, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyl7EkiblLNW",
        "outputId": "5e691699-37ed-4b76-92ad-6f06902620cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1: 100%|██████████| 6000/6000 [00:21<00:00, 279.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original Weights of the model**\n",
        "\n",
        "Keeping a copy of the original weights of the model will later help in comparison."
      ],
      "metadata": {
        "id": "vHBQXUVWo3Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_weights = {}\n",
        "for name, param in net.named_parameters():\n",
        "    original_weights[name] = param.clone().detach()"
      ],
      "metadata": {
        "id": "_lC8LYBfnE2f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing the model**"
      ],
      "metadata": {
        "id": "ciQIwVE7qw6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    correct = total = 0\n",
        "    wrong_counts = [0] * 10\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, desc='Testing'):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = net(x)\n",
        "            for idx, i in enumerate(output):\n",
        "                pred = torch.argmax(i)\n",
        "                actual = y[idx]\n",
        "                if pred == actual:\n",
        "                    correct += 1\n",
        "                else:\n",
        "                    wrong_counts[actual] += 1\n",
        "                total += 1\n",
        "\n",
        "    print(f'Accuracy: {round(correct/total, 2)}')\n",
        "    for idx, out in enumerate(wrong_counts):\n",
        "        print(f'Wrong counts for digit: {idx} is {out}')\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRj-QP_AqsQh",
        "outputId": "5bb40ee4-e090-4011-8838-51cd46e6e766"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 358.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96\n",
            "Wrong counts for digit: 0 is 11\n",
            "Wrong counts for digit: 1 is 20\n",
            "Wrong counts for digit: 2 is 54\n",
            "Wrong counts for digit: 3 is 68\n",
            "Wrong counts for digit: 4 is 24\n",
            "Wrong counts for digit: 5 is 18\n",
            "Wrong counts for digit: 6 is 40\n",
            "Wrong counts for digit: 7 is 55\n",
            "Wrong counts for digit: 8 is 9\n",
            "Wrong counts for digit: 9 is 87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LoRA Parametrization**"
      ],
      "metadata": {
        "id": "IC3b8605sf10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraParametrization(nn.Module):\n",
        "    def __init__ (self, device, features_in, features_out, rank: int=1, alpha: int=1):\n",
        "        super().__init__()\n",
        "        self.lora_a = nn.Parameter(torch.zeros(rank, features_out).to(device))\n",
        "        self.lora_b = nn.Parameter(torch.zeros(features_in, rank).to(device))\n",
        "\n",
        "        self.lora_a = nn.init.normal_(self.lora_a)\n",
        "\n",
        "        self.scale = alpha/rank\n",
        "        self.lora_enabled = True\n",
        "\n",
        "    def forward(self, orig_weights: torch.Tensor):\n",
        "        if self.lora_enabled:\n",
        "            return orig_weights + (torch.matmul(self.lora_b, self.lora_a).view(orig_weights.shape))*self.scale\n",
        "        else:\n",
        "            return orig_weights\n"
      ],
      "metadata": {
        "id": "W-oDvnihrKkN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding the parametrization in our network**"
      ],
      "metadata": {
        "id": "61K0akH40TxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils.parametrize as P\n",
        "\n",
        "def linear_layer_parametrization(layer, rank: int=1, alpha: int=1):\n",
        "    features_in, features_out = layer.weight.shape\n",
        "    return LoraParametrization(device, features_in, features_out)\n",
        "\n",
        "P.register_parametrization(net.linear1, 'weight', linear_layer_parametrization(net.linear1))\n",
        "P.register_parametrization(net.linear2, 'weight', linear_layer_parametrization(net.linear2))\n",
        "P.register_parametrization(net.linear3, 'weight', linear_layer_parametrization(net.linear3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q61hsQkH0JmW",
        "outputId": "e3bb020a-fd66-4102-b3a6-253ffc0a4922"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParametrizedLinear(\n",
              "  in_features=2000, out_features=10, bias=True\n",
              "  (parametrizations): ModuleDict(\n",
              "    (weight): ParametrizationList(\n",
              "      (0): LoraParametrization()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_disable_lora(flag:bool=True):\n",
        "    for layer in [net.linear1, net.linear2, net.linear3]:\n",
        "        layer.parametrizations['weight'][0].lora_enabled = flag"
      ],
      "metadata": {
        "id": "qijgQEie0zZz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Freezing the non-LoRA Parameters**"
      ],
      "metadata": {
        "id": "f2-Z2DO43Lh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the non-Lora parameters (which are self.lora_a and self.lora_b in our model)\n",
        "for name, param in net.named_parameters():\n",
        "    if 'lora' not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Load the MNIST dataset again, by keeping only the digit 9\n",
        "mnist_trainset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "required_indices = mnist_trainset.targets == 9\n",
        "\n",
        "mnist_trainset.data = mnist_trainset.data[required_indices]\n",
        "mnist_trainset.targets = mnist_trainset.targets[required_indices]\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Train the network with LoRA only on the digit 9 and only for 100 batches\n",
        "train(net, train_loader, epochs=1, total_iterations_limit=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9aJfcF92EQY",
        "outputId": "c86c26d3-da4a-4bd9-91ca-3088b57769f4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1:  99%|█████████▉| 99/100 [00:00<00:00, 185.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with LoRA enabled\n",
        "enable_disable_lora(True)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDovAFMH2w5k",
        "outputId": "70c9bd4b-7f85-48b9-c97c-3a47f5287c94"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 290.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n",
            "Wrong counts for digit: 0 is 11\n",
            "Wrong counts for digit: 1 is 21\n",
            "Wrong counts for digit: 2 is 68\n",
            "Wrong counts for digit: 3 is 81\n",
            "Wrong counts for digit: 4 is 155\n",
            "Wrong counts for digit: 5 is 53\n",
            "Wrong counts for digit: 6 is 49\n",
            "Wrong counts for digit: 7 is 147\n",
            "Wrong counts for digit: 8 is 37\n",
            "Wrong counts for digit: 9 is 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with LoRA disabled\n",
        "enable_disable_lora(False)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeuL-AcW289z",
        "outputId": "710e1c16-756e-4493-c402-a04b2bada07a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 358.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96\n",
            "Wrong counts for digit: 0 is 11\n",
            "Wrong counts for digit: 1 is 20\n",
            "Wrong counts for digit: 2 is 54\n",
            "Wrong counts for digit: 3 is 68\n",
            "Wrong counts for digit: 4 is 24\n",
            "Wrong counts for digit: 5 is 18\n",
            "Wrong counts for digit: 6 is 40\n",
            "Wrong counts for digit: 7 is 55\n",
            "Wrong counts for digit: 8 is 9\n",
            "Wrong counts for digit: 9 is 87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "goi-McLE3Brq"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}